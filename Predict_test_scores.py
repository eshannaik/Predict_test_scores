# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_6l4BDbOYHmybZxzsezG3ypg9jPXF6xj

# Test Score Prediction

### Importing libraries and reading dataset
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import keras
from keras.models import Model
from keras.layers import Dense,Input,BatchNormalization,Dropout,Activation

d = pd.read_csv("test_scores.csv")
d.head()

d.describe()

d.isnull().sum()

d.nunique()

d.shape

"""### Visualization"""

def count(d,a):
  plt.figure(figsize=(8,5))
  ax = sns.countplot(data=d,y=a,palette="Set3")
  
  total = 2133
  for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_width()/total)
    x = p.get_x() + p.get_width() + 0.5
    y = p.get_y() + p.get_height()/2
    ax.annotate(percentage,(x,y))
  
  plt.show()

count(d,"school_setting")

count(d,"lunch")

count(d,"school_type")

count(d,"gender")

count(d,"teaching_method")

ax = sns.barplot(y=d["n_student"],x=d["teaching_method"])
plt.show()

plt.style.use('seaborn-darkgrid')
fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (8,5))

sns.boxplot(x=d['pretest'],ax=ax1,linewidth=1.5)
sns.histplot(x=d.pretest,ax=ax2,kde=True)

ax1.tick_params(labelsize = 14)
ax2.tick_params(labelsize=14)

plt.style.use('seaborn-darkgrid')
fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (8,5))

sns.boxplot(x=d['posttest'],ax=ax1,linewidth=1.5)
sns.histplot(x=d.posttest,ax=ax2,kde=True)

ax1.tick_params(labelsize = 14)
ax2.tick_params(labelsize=14)

plt.figure(figsize = (8, 5))

sns.barplot(data=d,x="school_setting",y="posttest",color="red",label = 'PostTest')
sns.barplot(data=d,x="school_setting",y="pretest",color="grey",label = 'PreTest')

plt.xlabel(xlabel = 'School Setting', fontsize = 16, fontweight = 'bold')
plt.ylabel(ylabel = 'Test Scored', fontsize = 16, fontweight = 'bold')
plt.legend()
plt.show()

"""###Preprocessing"""

d.drop(["student_id","classroom","school"],inplace=True,axis=1)

d.head()

X = d.drop("posttest",axis=1)
y = d["posttest"]

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

categories = ['school_setting', 'school_type', 'teaching_method', 'gender', 'lunch']

one_hot = OneHotEncoder()
transformer = ColumnTransformer([('one_hot', one_hot, categories)],
                                remainder = 'passthrough')

X = transformer.fit_transform(X)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.2)

"""### Random Forest"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
rf.fit(X_train,y_train)

y_pred = rf.predict(X_test)

y_pred_rf=rf.score(X_test, y_test)
y_pred_rf

from sklearn.model_selection import RandomizedSearchCV

grid = {'n_estimators' : [10, 100, 200, 500, 1000, 1200],
        'max_depth' : [None, 5, 10, 20, 30],
        'max_features' : ['auto', 'sqrt'],
        'min_samples_split' : [2, 4, 6 ],
        'min_samples_leaf' : [1, 2, 4]}

rs_model = RandomizedSearchCV(estimator = rf, 
                              param_distributions = grid,
                              n_iter = 10,
                              cv = 5,
                              verbose = 2)

rs_model.fit(X_train, y_train)

rs_model.best_params_

rs_test_preds = rs_model.predict(X_test)

from sklearn.metrics import r2_score
r2 = r2_score(y_test, rs_test_preds)
r2